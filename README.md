# Keras-PyTorch-Speech-Recognition
A high-performance speech recognition system jointly built on Keras/TensorFlow and PyTorch frameworks, specifically optimized for short command recognition tasks (such as numerical commands like "seven" and control commands like "stop"). The system leverages Mel-Frequency Cepstral Coefficients (MFCC) for precise speech feature extraction—emulating human auditory characteristics to capture timbre and pitch information more effectively than raw audio waveforms—complemented by Z-score normalization to standardize feature distributions and accelerate model convergence. At its core lies an improved 2D Convolutional Neural Network (CNN) architecture, enhanced with L2 regularization and Dropout layers (rate=0.5) to mitigate overfitting, while Focal Loss addresses class imbalance issues and the RMSprop optimizer enables adaptive learning rate adjustment for stable training. It integrates end-to-end capabilities covering automated dataset construction (supporting folder scanning, stratified train/validation/test splitting), data augmentation (including time stretching, pitch shifting, and white noise addition via Librosa), and full-cycle model training—complete with callbacks for ModelCheckpoint (saving best weights), TensorBoard monitoring, and EarlyStopping to prevent stagnation. Additionally, the system features real-time voice recognition via microphone input, implementing on-the-fly MFCC feature extraction and preprocessing consistent with training data, followed by rapid inference using pre-trained models. Comprehensive performance visualization tools are also included, generating training/validation loss and accuracy curves, confusion matrices, and key metrics (accuracy, AUC) to facilitate in-depth result analysis and model tuning.
